{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":3938763,"sourceType":"datasetVersion","datasetId":857145}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Uso de uma RNA (CNN) para o diagnóstico de glaucoma #\n### Alunos: ###\n- Miguel Mendes Luna - 211026501\n- Pedro Eduardo - \n- Davy - ","metadata":{}},{"cell_type":"code","source":"# Importações básicas\nimport numpy as np\nimport pandas as pd\nimport os","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-29T16:18:07.589978Z","iopub.execute_input":"2024-06-29T16:18:07.590331Z","iopub.status.idle":"2024-06-29T16:18:07.595600Z","shell.execute_reply.started":"2024-06-29T16:18:07.590298Z","shell.execute_reply":"2024-06-29T16:18:07.594667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Explorando uma imagem\n\nFazendo algumas verificações acerca de um exemplo de imagem, tais como seu formato, seu tamanho (resolução), a imagem propriamente dita e uma representação matricial dos seus pixels com base no código RGB.","metadata":{}},{"cell_type":"code","source":"from numpy import asarray\n\nfrom PIL import Image\n\n# Carregando um exemplo de imagem\nimage = Image.open('/kaggle/input/glaucoma-detection/Fundus_Train_Val_Data/Fundus_Scanes_Sorted/Validation/Glaucoma_Positive/613.jpg') \n\n# Imprimindo alguns dados acerca da imagem\nprint(\"Formato da imagem: \" + str(image.format))\nprint(\"Modo da imagem: \" + str(image.mode))\nprint(\"Tamanho da imagem (pixels): \" + str(image.size))\n\n# Mostrando a imagem\ndisplay(image)\n\n# Mostrando os pixels da imagem matricialmente\npixels = asarray(image)\nprint(pixels)","metadata":{"execution":{"iopub.status.busy":"2024-06-29T16:18:07.654648Z","iopub.execute_input":"2024-06-29T16:18:07.655363Z","iopub.status.idle":"2024-06-29T16:18:09.149424Z","shell.execute_reply.started":"2024-06-29T16:18:07.655330Z","shell.execute_reply":"2024-06-29T16:18:09.148387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Tratamento de pixels\n\nAqui é feita a normalização do código RGB dos pixels para que representem um número entre -1 e 1. Note que, inicialmente, é calculada a média geral dos valores correspondentes dos pixels, para então subtraí-la de cada valor, a fim de deixar os valores resultantes \"ao redor\" de zero, de forma que a média global passou a ser nula. Em seguida, dividiu-se todos os valores correspondentes por 255 (máximo valor no RGB), para que os valores ficassem entre 0 e 1 em módulo.","metadata":{}},{"cell_type":"code","source":"# global centering\n\n# calculate global mean\nmean = pixels.mean()\nprint('Mean: %.3f' % mean)\nprint('Min: %.3f, Max: %.3f' % (pixels.min(), pixels.max()))\n# global centering of pixels\npixels = pixels - mean\n# confirm it had the desired effect\nmean = pixels.mean()\nprint('Mean: %.3f' % mean)\nprint('Min: %.3f, Max: %.3f' % (pixels.min(), pixels.max()))\nprint(pixels)\n\n\n# example of pixel normalization\n# confirm pixel range is 0-255\nprint('Data Type: %s' % pixels.dtype)\nprint('Min: %.3f, Max: %.3f' % (pixels.min(), pixels.max()))\n# convert from integers to floats\npixels = pixels.astype('float32')\n# normalize to the range 0-1\npixels /= 255.0\nmean = pixels.mean()\nprint('pixel mean = ', mean)\n\n# confirm the normalization\nprint('Min: %.3f, Max: %.3f' % (pixels.min(), pixels.max()))\nprint(pixels)","metadata":{"execution":{"iopub.status.busy":"2024-06-29T16:18:09.150645Z","iopub.execute_input":"2024-06-29T16:18:09.150964Z","iopub.status.idle":"2024-06-29T16:18:09.333415Z","shell.execute_reply.started":"2024-06-29T16:18:09.150938Z","shell.execute_reply":"2024-06-29T16:18:09.332456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualização parcial\n\nVisualização da imagem original quando comparada à imagem após a normalização dos pixels.","metadata":{}},{"cell_type":"code","source":"# Visualization\nimport matplotlib.pyplot as plt\nfig, (ax0, ax1) = plt.subplots(1, 2)\nax0.imshow(image)\nax0.axis('off')\nax0.set_title('image')\nax1.imshow(pixels)\nax1.axis('off')\nax1.set_title('result')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-29T16:18:09.335959Z","iopub.execute_input":"2024-06-29T16:18:09.336265Z","iopub.status.idle":"2024-06-29T16:18:11.463707Z","shell.execute_reply.started":"2024-06-29T16:18:09.336240Z","shell.execute_reply":"2024-06-29T16:18:11.462764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Declaração de diretórios\nTRAIN_DIR = '/kaggle/input/glaucoma-detection/Fundus_Train_Val_Data/Fundus_Scanes_Sorted/Train'\nTEST_DIR = '/kaggle/input/glaucoma-detection/Fundus_Train_Val_Data/Fundus_Scanes_Sorted/Validation'","metadata":{"execution":{"iopub.status.busy":"2024-06-29T16:18:11.470769Z","iopub.execute_input":"2024-06-29T16:18:11.471085Z","iopub.status.idle":"2024-06-29T16:18:11.480314Z","shell.execute_reply.started":"2024-06-29T16:18:11.471060Z","shell.execute_reply":"2024-06-29T16:18:11.479559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Construindo a rede neural\n\nfrom tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers import Dense, Activation, Flatten, Dropout\nfrom keras.models import Sequential, Model \nfrom keras.optimizers import SGD, Adam\nfrom keras.callbacks import TensorBoard\nfrom keras import metrics\nimport keras\nimport matplotlib.pyplot as plt\n\nHEIGHT = 300\nWIDTH = 300\n\nBATCH_SIZE = 8\nclass_list = [\"class_1\", \"class_2\"]\nFC_LAYERS = [1024, 512, 256]\ndropout = 0.5\nNUM_EPOCHS = 100\nBATCH_SIZE = 8\n\ndef build_model(base_model, dropout, fc_layers, num_classes):\n    for layer in base_model.layers:\n        layer.trainable = False\n\n    x = base_model.output\n    x = Flatten()(x)\n    for fc in fc_layers:\n        # print(fc)\n        x = Dense(fc, activation='relu')(x)\n        x = Dropout(dropout)(x)\n    preditions = Dense(num_classes, activation='softmax')(x)\n    finetune_model = Model(inputs = base_model.input, outputs = preditions)\n    return finetune_model\n\nbase_model_1 = ResNet50(weights = 'imagenet',\n                       include_top = False,\n                       input_shape = (HEIGHT, WIDTH, 3))\n\ntrain_datagen = ImageDataGenerator(preprocessing_function = preprocess_input,\n                                   rotation_range = 90,\n                                   horizontal_flip = True,\n                                   vertical_flip = True,\n                                   width_shift_range=0.2,\n                                   height_shift_range=0.2,\n                                   zoom_range=0.1,)\n\ntest_datagen = ImageDataGenerator(preprocessing_function = preprocess_input,\n                                  rotation_range = 90,\n                                  horizontal_flip = True,\n                                  vertical_flip = False)\n\ntrain_generator = train_datagen.flow_from_directory(TRAIN_DIR,\n                                                    target_size = (HEIGHT, WIDTH),\n                                                    batch_size = BATCH_SIZE)\n\ntest_generator = test_datagen.flow_from_directory(TEST_DIR,\n                                                  target_size = (HEIGHT, WIDTH),\n                                                  batch_size = BATCH_SIZE)\n\n\n\n\nresnet50_model = build_model(base_model_1,\n                                      dropout = dropout,\n                                      fc_layers = FC_LAYERS,\n                                      num_classes = len(class_list))\n\nadam = Adam(learning_rate = 0.00001)\nresnet50_model.compile(adam, loss=\"binary_crossentropy\", metrics=[\"accuracy\", metrics.mean_squared_error, metrics.F1Score])\n\nfilepath = \"./checkpoints\" + \"RestNet50\" + \"_model_weights.keras\"\ncheckpoint = keras.callbacks.ModelCheckpoint(filepath, monitor = [\"acc\"], verbose= 1, mode = \"max\")\ncb=TensorBoard(log_dir=(\"/home/ubuntu/\"))\ncallbacks_list = [checkpoint, cb]\n\n# print(train_generator.class_indices)\n\n# resnet50_model.summary()","metadata":{"execution":{"iopub.status.busy":"2024-06-29T16:18:11.481417Z","iopub.execute_input":"2024-06-29T16:18:11.481681Z","iopub.status.idle":"2024-06-29T16:18:12.824210Z","shell.execute_reply.started":"2024-06-29T16:18:11.481659Z","shell.execute_reply":"2024-06-29T16:18:12.823399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Treinamento\nhistory = resnet50_model.fit(train_generator, epochs = NUM_EPOCHS, steps_per_epoch = 100, \n                                       shuffle = True, validation_data = test_generator)","metadata":{"execution":{"iopub.status.busy":"2024-06-29T16:54:57.341456Z","iopub.execute_input":"2024-06-29T16:54:57.341736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib as pyplot\npyplot.plot(history.history['accuracy'])\npyplot.plot(history.history['f1_score'])\npyplot.plot(history.history['mean_squared_error'])\npyplot.show()","metadata":{},"execution_count":null,"outputs":[]}]}